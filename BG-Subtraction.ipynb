{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### https://medium.com/@adamaulia/object-tracking-using-opencv-python-windows-616fb23da720"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:54:37.984031Z",
     "start_time": "2019-10-19T12:54:37.889141Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:56:00.603578Z",
     "start_time": "2019-10-19T12:56:00.596532Z"
    }
   },
   "outputs": [],
   "source": [
    "VID_PATH = 'video2.avi'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting boxes using BGSubtraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:56:24.945598Z",
     "start_time": "2019-10-19T12:56:01.213761Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Will give boxes for each frame and simultaneously extract background\"\"\"\n",
    "\n",
    "cap  = cv2.VideoCapture(VID_PATH)\n",
    "fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "fgbg = cv2.createBackgroundSubtractorKNN()\n",
    "\n",
    "ret, frame = cap.read()\n",
    "all_conts = []\n",
    "\n",
    "avg2 = np.float32(frame) #BG-Ext\n",
    "\n",
    "while ret:\n",
    "    \n",
    "    #Background extraction\n",
    "    try:\n",
    "        cv2.accumulateWeighted(frame, avg2, 0.01)\n",
    "    except:\n",
    "        break\n",
    "    #if ret is true than no error with cap.isOpened\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        #apply background substraction\n",
    "        fgmask = fgbg.apply(frame)  \n",
    "        \n",
    "        #apply contours on foreground\n",
    "        (contours, hierarchy) = cv2.findContours(fgmask.copy(), cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "        \n",
    "        contours = np.array([np.array(cv2.boundingRect(c)) for c in contours if cv2.contourArea(c) >= 500])\n",
    "        all_conts.append(contours)\n",
    "        for c in contours:\n",
    "            \n",
    "            #get bounding box from countour\n",
    "            (x, y, w, h) = c\n",
    "            \n",
    "            cv2.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "        \n",
    "#         cv2.imshow('rgb', frame)\n",
    "        \n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n",
    "background = cv2.convertScaleAbs(avg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object tracking "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:56:55.783906Z",
     "start_time": "2019-10-19T12:56:55.767133Z"
    }
   },
   "outputs": [],
   "source": [
    "def distance(p1, p2):\n",
    "    return np.linalg.norm(p1 - p2, axis=1)\n",
    "\n",
    "def get_nearest(p1, points):\n",
    "    \"\"\"returns index of the point in *points* that is closest to p1\"\"\"\n",
    "    return np.argmin(distance(p1, points))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:57:16.873993Z",
     "start_time": "2019-10-19T12:57:16.856254Z"
    }
   },
   "outputs": [],
   "source": [
    "class box:\n",
    "    def __init__(self, coords, time):\n",
    "        self.coords = coords #coordinates\n",
    "        self.time   = time #nth frame/time\n",
    "        \n",
    "class moving_obj:\n",
    "    def __init__(self, starting_box):\n",
    "        self.boxes = [starting_box]\n",
    "    \n",
    "    def add_box(self, box):\n",
    "        self.boxes.append(box)\n",
    "    \n",
    "    def last_coords(self):\n",
    "        return self.boxes[-1].coords\n",
    "    \n",
    "    def age(self, curr_time):\n",
    "        last_time = self.boxes[-1].time\n",
    "        return curr_time - last_time    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:59:11.677512Z",
     "start_time": "2019-10-19T12:59:11.404290Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Will associate boxes into objects\"\"\"\n",
    "#old - boxes in the previous frame\n",
    "#new - boxes in the current frame\n",
    "\n",
    "THRESHOLD = 10\n",
    "moving_objs = []\n",
    "\n",
    "for curr_time, new_boxes in enumerate(all_conts): #iterating over frames\n",
    "    if len(new_boxes) != 0: #if not empty\n",
    "        new_assocs = [None]*len(new_boxes) #all new boxes initially arent associated with any moving_objs\n",
    "        obj_coords = np.array([obj.last_coords() for obj in moving_objs if obj.age(curr_time)<THRESHOLD])\n",
    "        unexp_idx = -1 #index of unexpired obj in moving_objs\n",
    "        for obj_idx, obj in enumerate(moving_objs):\n",
    "            if obj.age(curr_time) < THRESHOLD: #checking only unexpired objects\n",
    "                unexp_idx += 1\n",
    "                nearest_new = get_nearest(obj.last_coords(), new_boxes) #nearest box to obj\n",
    "                nearest_obj = get_nearest(new_boxes[nearest_new], obj_coords) #nearest obj to box\n",
    "\n",
    "                if nearest_obj==unexp_idx: #both closest to each-other\n",
    "                    #associate\n",
    "                    new_assocs[nearest_new] = obj_idx\n",
    "    \n",
    "    \n",
    "    for new_idx, new_coords in enumerate(new_boxes):\n",
    "        new_assoc = new_assocs[new_idx]\n",
    "        new_box = box(new_coords, curr_time)\n",
    "\n",
    "        if new_assoc is not None: \n",
    "            #associate new box to moving_obj\n",
    "            moving_objs[new_assoc].add_box(new_box)\n",
    "        else: \n",
    "            #add a fresh, new moving_obj to moving_objs\n",
    "            new_moving_obj = moving_obj(new_box)\n",
    "            moving_objs.append(new_moving_obj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:59:14.252143Z",
     "start_time": "2019-10-19T12:59:14.248987Z"
    }
   },
   "outputs": [],
   "source": [
    "#Removing objects that occur for a very small duration\n",
    "MIN_SECONDS = 2 #seconds\n",
    "MIN_FRAMES = MIN_SECONDS*fps\n",
    "\n",
    "moving_objs = [obj for obj in moving_objs if (obj.boxes[-1].time-obj.boxes[0].time)>MIN_FRAMES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overlaying moving objects on background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:59:24.122376Z",
     "start_time": "2019-10-19T12:59:24.106915Z"
    }
   },
   "outputs": [],
   "source": [
    "def cut(image, coords):\n",
    "    (x, y, w, h) = coords\n",
    "    return image[y:y+h,x:x+w]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:59:30.451808Z",
     "start_time": "2019-10-19T12:59:30.448859Z"
    }
   },
   "outputs": [],
   "source": [
    "def overlay(frame, image, coords):\n",
    "    (x, y, w, h) = coords\n",
    "    frame[y:y+h,x:x+w] = cut(image, coords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T12:59:32.703257Z",
     "start_time": "2019-10-19T12:59:32.690691Z"
    }
   },
   "outputs": [],
   "source": [
    "import time as tm\n",
    "def sec2HMS(seconds):\n",
    "    return tm.strftime('%M:%S', tm.gmtime(seconds))\n",
    "\n",
    "def frame2HMS(n_frame, fps):\n",
    "    return sec2HMS(float(n_frame)/float(fps))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T13:02:42.460202Z",
     "start_time": "2019-10-19T13:02:41.896758Z"
    }
   },
   "outputs": [],
   "source": [
    "max_orig_len = max(obj.boxes[-1].time for obj in moving_objs)\n",
    "max_duration = max((obj.boxes[-1].time - obj.boxes[0].time) for obj in moving_objs)\n",
    "#max_duration of a moving_obj. This is taken as the duration of the final summary\n",
    "start_times = [obj.boxes[0].time for obj in moving_objs]\n",
    "\n",
    "INTERVAL = 10 #seconds\n",
    "DIVISIONS = int(max_orig_len/(INTERVAL))\n",
    "GAP_BW_DIVISIONS = 2 #seconds\n",
    "\n",
    "\n",
    "final_video  = [background.copy() for _ in range(max_duration+int(DIVISIONS*GAP_BW_DIVISIONS)+10)] #initializing frames of final video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T13:04:09.027324Z",
     "start_time": "2019-10-19T13:04:04.827872Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Crop moving objects from main video and overlay them on the backgroung\"\"\"\n",
    "cap  = cv2.VideoCapture(VID_PATH)\n",
    "# fgbg = cv2.createBackgroundSubtractorMOG2()\n",
    "\n",
    "ret, frame = cap.read() #original video\n",
    "# all_conts = []\n",
    "\n",
    "all_texts = []\n",
    "\n",
    "vid_time = -1\n",
    "while ret:\n",
    "    vid_time += 1\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret==True:\n",
    "        \n",
    "        for obj_idx, mving_obj in enumerate(moving_objs):\n",
    "            if mving_obj.boxes: #non-empty\n",
    "                first_box = mving_obj.boxes[0]\n",
    "                \n",
    "                if(first_box.time == vid_time):\n",
    "                    final_time = first_box.time - start_times[obj_idx] + int(int(start_times[obj_idx]/int(INTERVAL*fps))*GAP_BW_DIVISIONS*fps)\n",
    "                    \n",
    "                    overlay(final_video[final_time-1], frame, first_box.coords)\n",
    "                    (x, y, w, h) = first_box.coords\n",
    "                    \n",
    "#                     all_texts.append((final_time-1, frame2HMS(first_box.time, fps), (x, y-10))) #Above\n",
    "                    all_texts.append((final_time-1, frame2HMS(first_box.time, fps), (x+int(w/2), y+int(h/2)))) #Centre\n",
    "    \n",
    "                    del(mving_obj.boxes[0])\n",
    "        if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "            break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T13:06:38.421630Z",
     "start_time": "2019-10-19T13:06:38.328425Z"
    }
   },
   "outputs": [],
   "source": [
    "#annotating moving objects\n",
    "for (t, text, org) in all_texts:\n",
    "    cv2.putText(final_video[t], text, org, cv2.FONT_HERSHEY_SIMPLEX, 0.5, (252, 240,3 ), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T13:06:41.818168Z",
     "start_time": "2019-10-19T13:06:40.042779Z"
    }
   },
   "outputs": [],
   "source": [
    "out = cv2.VideoWriter('summary.avi',cv2.VideoWriter_fourcc(*'DIVX'), fps, (background.shape[1],background.shape[0]))\n",
    "\n",
    "for frame in final_video:\n",
    "#     cv2.imshow('Video summary',frame)\n",
    "    out.write(frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord(\"q\"):\n",
    "        break\n",
    "#     tm.sleep(1/30) #TODO: FPS\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-19T13:04:52.511825Z",
     "start_time": "2019-10-19T13:04:52.505093Z"
    }
   },
   "outputs": [],
   "source": [
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: Remove overlapping\n",
    "#mog vs KNN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
